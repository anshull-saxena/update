{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WZP2hZINH9F5"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "import warnings\n",
    "import copy\n",
    "import random\n",
    "from keras import layers, models\n",
    "from keras.utils import to_categorical\n",
    "from keras.datasets import mnist\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bDosArdZH9F6"
   },
   "outputs": [],
   "source": [
    "def anneal(alpha, mask_a, d=2, lower_bound=20, upper_bound=10):\n",
    "    alpha = alpha.copy()\n",
    "    mask_b = np.random.choice([True, False], size=alpha.shape)\n",
    "    mask = mask_a ^ mask_b\n",
    "    step = np.random.randint(0, d+1, size=alpha.shape)/225.\n",
    "    start_h = 0\n",
    "    end_h = 1\n",
    "    start_w = np.random.randint(0, lower_bound)\n",
    "    end_w = np.random.randint(len(alpha) - upper_bound, len(alpha))\n",
    "    masksliced = np.zeros(alpha.shape, dtype=bool)\n",
    "    masksliced[start_w:end_w] = mask[start_w:end_w]\n",
    "    alpha[masksliced] += step[masksliced]\n",
    "    return alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a7SOOQXrH9F7"
   },
   "outputs": [],
   "source": [
    "def rmse_score(model, user_ind,user_embeddings, item_embeddings, alpha):\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        alpha= alpha.reshape(-1)\n",
    "        predicted_ratings = torch.matmul(user_embeddings[user_ind], item_embeddings.T)\n",
    "        interaction_tensor = torch.tensor(alpha, dtype=torch.float32)\n",
    "        target= interaction_tensor\n",
    "        rmse = np.sqrt(mean_squared_error(target, predicted_ratings))  # Compute RMSE\n",
    "\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oDzoqahlH9F7"
   },
   "outputs": [],
   "source": [
    "def fitness(user_embeddings, item_embeddings, alpha_population, model, lambda_value = 0.1):\n",
    "    fitness_values = []\n",
    "    for alpha_ind, alpha in alpha_population:\n",
    "        # here alpha represents that one pparticular user's interaction with all the items\n",
    "        # alpha_population represents manipulated interaction matrix for some users\n",
    "\n",
    "        error = lambda_value * rmse_score(model, alpha_ind ,user_embeddings, item_embeddings, alpha)\n",
    "        alpha_fitness = 1 + error - np.linalg.norm(alpha)\n",
    "        fitness_values.append(abs(np.max(alpha_fitness)))\n",
    "    return fitness_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YO6i8uzgH9F7"
   },
   "outputs": [],
   "source": [
    "def twoplayergame_sa(user_embeddings, item_embeddings, interaction_matrix, model):\n",
    "    maxpayoff = 0\n",
    "    exitloop = False\n",
    "    Tmax = 10\n",
    "    Tmin = 5\n",
    "    v = 50\n",
    "    p = 0.2\n",
    "    mask = np.random.choice([True,False], size=interaction_matrix[0].shape)\n",
    "    Tcurr = Tmax\n",
    "    population = [(i,interaction_matrix[i]) for i in range(interaction_matrix.shape[0])]\n",
    "    random.shuffle(population)\n",
    "    pop_size = len(population) // 3\n",
    "    ac = population[:pop_size].copy()\n",
    "    ag = population[pop_size:2*pop_size].copy()\n",
    "    an = population[2*pop_size:].copy()\n",
    "    evalc = fitness(user_embeddings, item_embeddings, ac, model)\n",
    "    maxpayoff = max(fitness(user_embeddings, item_embeddings, ag, model))\n",
    "    while not exitloop:\n",
    "        evalg = fitness(user_embeddings, item_embeddings, ag,model)\n",
    "        curr_index = np.argmax(evalg)\n",
    "        currpayoff = evalg[curr_index]\n",
    "        print(\"The current Payoff is:\",currpayoff)\n",
    "        if abs(currpayoff - maxpayoff) < 0.1:\n",
    "            maxpayoff = currpayoff\n",
    "            while Tcurr >= Tmin:\n",
    "                i = 1\n",
    "                while i <= v:\n",
    "                    temp = []\n",
    "                    for ind, interaction in ac:\n",
    "                        temp.append((ind,anneal(interaction,mask)))\n",
    "                    an = temp.copy()\n",
    "                    evaln = fitness(user_embeddings, item_embeddings, an,model)\n",
    "                    if max(evaln) > max(evalc):\n",
    "                        ac = an.copy()\n",
    "                        evalc = evaln.copy()\n",
    "                        if max(evalg) < max(evaln):\n",
    "                            ag = an.copy()\n",
    "                            evalg = evaln.copy()\n",
    "                    else:\n",
    "                        if np.random.random() <= np.exp((max(evaln) - max(evalc)) / Tcurr):\n",
    "                            ac = an.copy()\n",
    "                            evalc = evaln.copy()\n",
    "                    i += 1\n",
    "                Tcurr *= p\n",
    "            ag = ac.copy()\n",
    "        else:\n",
    "            exitloop = True\n",
    "    return ag[np.argmax(fitness(user_embeddings, item_embeddings, ag, model))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H49aTEqqH9F8"
   },
   "outputs": [],
   "source": [
    "def generate_manipulated_data(matrix, A_s):\n",
    "    #here A_s is manippulated data for some users\n",
    "    alphas=[]\n",
    "    for i in range(len(A_s)):\n",
    "        alphas.append(A_s[i][1])\n",
    "    print(alphas)\n",
    "    X_manipulated = np.concatenate([matrix, alphas], axis=0)\n",
    "    return X_manipulated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qHDZ_toIH9F8"
   },
   "outputs": [],
   "source": [
    "def adversarial_manipulation(user_embeddings, item_embeddings, interaction_matrix, model,M):\n",
    "    A_s = []\n",
    "    for i in range(1, M+1):\n",
    "        a_i = twoplayergame_sa(user_embeddings, item_embeddings, interaction_matrix, model)\n",
    "        A_s.append(a_i)\n",
    "\n",
    "    interaction_matrix_manipulated= generate_manipulated_data(interaction_matrix, A_s)\n",
    "    return interaction_matrix_manipulated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "shyuj8NZH9F8"
   },
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dOtUXdGuH9F9"
   },
   "source": [
    "1. Normal - with the normal interaction matrix we generate recommendations for some existing user/ new user\n",
    "2. manipulated -\n",
    "3. secure -  train the gcn with adversarial interaction matrix and generate recommendations for some existing user/ new user\n",
    "\n",
    "The metric can be rmse or the top k predictions produced in each case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "elfx4152H9F9",
    "outputId": "2cfd1b04-4d83-4e21-d71a-d14358ae44f6"
   },
   "outputs": [],
   "source": [
    "!pip install torch_geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eCZLkYhkH9F-"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Set device: use GPU if available, otherwise fallback to CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Define base path to save trained models and other outputs\n",
    "save_base_path = \"/path/to/save\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iPmB_L4vH9F-"
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import requests\n",
    "from io import BytesIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wuQrsiEJH9F-",
    "outputId": "c687e46d-5f48-48e5-ad7a-3aa38e21ef8b"
   },
   "outputs": [],
   "source": [
    "url = 'https://files.grouplens.org/datasets/movielens/ml-latest-small.zip'\n",
    "\n",
    "# Download the dataset\n",
    "response = requests.get(url)\n",
    "zip_file = zipfile.ZipFile(BytesIO(response.content))\n",
    "\n",
    "# Extract the ratings and movies CSV files\n",
    "ratings = pd.read_csv(zip_file.open('ml-latest-small/ratings.csv'))\n",
    "movies = pd.read_csv(zip_file.open('ml-latest-small/movies.csv'))\n",
    "\n",
    "# Preview the datasets\n",
    "print(ratings.head())\n",
    "print(movies.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5eeZxhObH9F-"
   },
   "outputs": [],
   "source": [
    "# Get unique users and items from the ratings dataset\n",
    "users = ratings['userId'].unique()\n",
    "items = ratings['movieId'].unique()\n",
    "\n",
    "# Create mappings from user/item IDs to indices (used for embedding)\n",
    "user_to_idx = {user: idx for idx, user in enumerate(users)}\n",
    "item_to_idx = {item: idx for idx, item in enumerate(items)}\n",
    "\n",
    "# Convert user and item IDs in ratings to indices\n",
    "ratings['user_idx'] = ratings['userId'].apply(lambda x: user_to_idx[x])\n",
    "ratings['item_idx'] = ratings['movieId'].apply(lambda x: item_to_idx[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Bc_FqO7VH9F-",
    "outputId": "f32b1184-f10b-4b45-d71d-7233138d6691"
   },
   "outputs": [],
   "source": [
    "print(users.size)\n",
    "print(items.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x23zzIcgH9F-",
    "outputId": "f4171362-b007-483e-e668-f8f0cfc7a1aa"
   },
   "outputs": [],
   "source": [
    "print(ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "upMOEdBEH9F-"
   },
   "outputs": [],
   "source": [
    "# Create a pivot table where rows are users, columns are items, and values are ratings\n",
    "interaction_matrix = ratings.pivot(index='user_idx', columns='item_idx', values='rating').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dRfFCwDGH9F-",
    "outputId": "f99dfd43-5ad3-4d44-8296-afa07a69b689"
   },
   "outputs": [],
   "source": [
    "interaction_array= np.array(interaction_matrix)\n",
    "print(interaction_array)\n",
    "print('matrix dimensions : ', interaction_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zLcxkH3uH9F_"
   },
   "outputs": [],
   "source": [
    "class UserItemDataset(Dataset):\n",
    "    def __init__(self, ratings):\n",
    "        self.ratings = ratings\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ratings)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.ratings.iloc[idx]\n",
    "        return {\n",
    "            'user_idx': torch.tensor(row['user_idx'], dtype=torch.long),\n",
    "            'item_idx': torch.tensor(row['item_idx'], dtype=torch.long),\n",
    "            'rating': torch.tensor(row['rating'], dtype=torch.float),\n",
    "        }\n",
    "\n",
    "# Create train, validation, and test splits (80% train, 10% validation, 10% test)\n",
    "train_size = int(len(ratings))\n",
    "val_size = int(0 * len(ratings))\n",
    "# test_size = len(ratings) - train_size - val_size\n",
    "\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(ratings, [train_size, val_size])\n",
    "\n",
    "# Create data loaders for batching\n",
    "train_loader = DataLoader(UserItemDataset(ratings.iloc[train_dataset.indices]), batch_size=32, shuffle=True)\n",
    "# val_loader = DataLoader(UserItemDataset(ratings.iloc[val_dataset.indices]), batch_size=32, shuffle= True)\n",
    "# test_loader = DataLoader(UserItemDataset(ratings.iloc[test_dataset.indices]), batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OKApT5wiH9F_"
   },
   "outputs": [],
   "source": [
    "class MFModel(nn.Module):\n",
    "    def __init__(self, num_users, num_items, embedding_size):\n",
    "        super(MFModel, self).__init__()\n",
    "        # Create embedding layers for users and items\n",
    "        self.user_embedding = nn.Embedding(num_users, embedding_size)\n",
    "        self.item_embedding = nn.Embedding(num_items, embedding_size)\n",
    "\n",
    "    def forward(self, user_ids, item_ids):\n",
    "        # Get user and item embeddings\n",
    "        user_embedding = self.user_embedding(user_ids)\n",
    "        item_embedding = self.item_embedding(item_ids)\n",
    "        # Compute the dot product between user and item embeddings\n",
    "        dot_product = (user_embedding * item_embedding).sum(dim=1)\n",
    "        return dot_product\n",
    "\n",
    "# Initialize the model with number of users, items, and the embedding size\n",
    "num_users = len(users)\n",
    "num_items = len(items)\n",
    "embedding_size = 50  # This is a tunable hyperparameter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9YKB4hIkI6NB"
   },
   "outputs": [],
   "source": [
    "mf_model1 = MFModel(num_users, num_items, embedding_size).to(device)\n",
    "optimizer = optim.Adam(mf_model1.parameters(), lr=0.001)  # Adam optimizer\n",
    "loss_fn = nn.MSELoss()  # Loss function (Mean Squared Error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w_-TEWvNH9F_",
    "outputId": "6bf5964d-02a0-4ca4-eaa5-6a9929420978"
   },
   "outputs": [],
   "source": [
    "print(num_users, num_items, mf_model1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rMCMJnQhH9F_"
   },
   "outputs": [],
   "source": [
    "def train_mf_model(model, train_loader, optimizer, criterion, num_epochs=10):\n",
    "    model.train()  # Set the model to training mode\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0\n",
    "        for batch in train_loader:\n",
    "            user_ids = batch['user_idx'].to(device)\n",
    "            item_ids = batch['item_idx'].to(device)\n",
    "            ratings = batch['rating'].to(device)\n",
    "\n",
    "            optimizer.zero_grad()  # Zero the gradients\n",
    "            preds = model(user_ids, item_ids)  # Forward pass\n",
    "            loss = criterion(preds, ratings)  # Compute loss\n",
    "            loss.backward()  # Backpropagation\n",
    "            optimizer.step()  # Gradient descent step\n",
    "            total_loss += loss.item()  # Accumulate loss\n",
    "\n",
    "        print(f'Epoch {epoch + 1}/{num_epochs}, Loss: {total_loss / len(train_loader):.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7qUj1bgRJJnC",
    "outputId": "eaec4aa8-7a96-44a8-88cc-40ed8c3276a4"
   },
   "outputs": [],
   "source": [
    "train_mf_model(mf_model1, train_loader, optimizer, loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Veluz8PwH9F_"
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    user_embeddings = mf_model1.user_embedding.weight.cpu().numpy()\n",
    "    item_embeddings = mf_model1.item_embedding.weight.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xnNLRizPH9F_",
    "outputId": "2d7486c2-680d-443b-a1b1-808f4550fb07"
   },
   "outputs": [],
   "source": [
    "print(user_embeddings.shape)\n",
    "print(user_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OW05ZMQcH9F_"
   },
   "outputs": [],
   "source": [
    "def create_graph_data(ratings,num_users,user_embeddings,item_embeddings):\n",
    "    user_item_edges = ratings[['user_idx', 'item_idx']].values.T  # Create edges between user-item pairs\n",
    "\n",
    "    user_item_edges[1] += num_users\n",
    "\n",
    "    # Create edge index (format required by torch_geometric)\n",
    "    edge_index = torch.tensor(user_item_edges, dtype=torch.long)\n",
    "\n",
    "    # Concatenate user and item embeddings to form node features\n",
    "    node_features = torch.cat([torch.tensor(user_embeddings, dtype=torch.float), torch.tensor(item_embeddings, dtype=torch.float)], dim=0)\n",
    "\n",
    "    print(node_features.shape)\n",
    "    print(user_item_edges.shape)\n",
    "    print(user_item_edges)\n",
    "\n",
    "    # Create the PyTorch Geometric data object (x: node features, edge_index: graph edges)\n",
    "    train_graph_data = Data(x=node_features, edge_index=edge_index)\n",
    "    return train_graph_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dYDNmZNVMAVd",
    "outputId": "0852933b-8a0f-4c63-82f6-faabb34665fa"
   },
   "outputs": [],
   "source": [
    "train_graph_data = create_graph_data(ratings,num_users,user_embeddings,item_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WIQ7Wf5AH9F_"
   },
   "outputs": [],
   "source": [
    "class GCNModel(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super(GCNModel, self).__init__()\n",
    "        # First graph convolutional layer\n",
    "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
    "        # Second graph convolutional layer\n",
    "        self.conv2 = GCNConv(hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, data):\n",
    "        # Forward pass through the first graph convolutional layer\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = torch.relu(x)  # Apply ReLU non-linearity\n",
    "        # Forward pass through the second graph convolutional layer\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A6tGkR3CH9F_"
   },
   "outputs": [],
   "source": [
    "# Initialize the GCN model\n",
    "model1 = GCNModel(in_channels=embedding_size, hidden_channels=64, out_channels=32).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qrkeq_cRH9GA"
   },
   "outputs": [],
   "source": [
    "gcn_optimizer = optim.Adam(model1.parameters(), lr=0.01)\n",
    "gcn_loss_fn = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6TH1pAHLH9GA"
   },
   "outputs": [],
   "source": [
    "def train_gcn_model(model, train_graph, optimizer, criterion, interaction_matrix,num_epochs=30):\n",
    "    model.train()  # Set model to training mode\n",
    "    user_embed=[]\n",
    "    item_embed=[]\n",
    "    for epoch in range(num_epochs):\n",
    "        optimizer.zero_grad()  # Zero the gradients\n",
    "        output = model(train_graph)  # Forward pass through the GCN\n",
    "\n",
    "\n",
    "        #print('output dimension',output.shape)\n",
    "        # Assuming user_idx and item_idx are indices of user-item pairs\n",
    "        user_indices = ratings['user_idx'].unique()  # Indices for users\n",
    "        item_indices = ratings['item_idx'].unique()  # Indices for items\n",
    "\n",
    "\n",
    "        #print('user indices dimension check',user_indices.shape)\n",
    "        #print('item indices dimension check',item_indices.shape)\n",
    "        # Get embeddings for the relevant user-item pairs\n",
    "        user_embeddings = output[user_indices]  # Shape: (N, embedding_size)\n",
    "        item_embeddings = output[item_indices + num_users]  # Shift by num_users for items\n",
    "\n",
    "        # Compute predicted ratings\n",
    "        predicted_ratings = torch.matmul(user_embeddings, item_embeddings.T) # Dot product\n",
    "\n",
    "        # Get target ratings from interaction matrix\n",
    "        interaction_tensor = torch.tensor(interaction_matrix.values, dtype=torch.float32)\n",
    "        target= interaction_tensor\n",
    "        #target = interaction_tensor[user_indices, item_indices].view(-1)  # Flatten to match\n",
    "\n",
    "        # Compute loss\n",
    "        loss = criterion(predicted_ratings, target)\n",
    "        loss.backward()  # Backpropagation\n",
    "        optimizer.step()  # Gradient descent step\n",
    "\n",
    "        user_embed= user_embeddings\n",
    "        item_embed= item_embeddings\n",
    "\n",
    "        print(f'Epoch {epoch + 1}/{num_epochs}, Loss: {loss.item():.4f}')\n",
    "\n",
    "    return user_embed, item_embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EJUJ2RkBH9GA",
    "outputId": "5430f1a0-80f4-4c02-ca2f-35f88a86e360"
   },
   "outputs": [],
   "source": [
    "user_embeddings, item_embeddings= train_gcn_model(model1, train_graph_data, gcn_optimizer, gcn_loss_fn, interaction_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lskzzxsKH9GA",
    "outputId": "2a8369fc-615e-466d-e349-e03849281c64"
   },
   "outputs": [],
   "source": [
    "print(user_embeddings)\n",
    "print(user_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EaV6s7uRjGVG",
    "outputId": "fa757e17-51a9-42e5-8e74-8e8166ecee16"
   },
   "outputs": [],
   "source": [
    "print(item_embeddings)\n",
    "print(item_embeddings.shape)\n",
    "old_item_embeddings= item_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wJULtSHTH9GA"
   },
   "outputs": [],
   "source": [
    "def evaluate_gcn_model(model, user_embeddings, item_embeddings, interaction_matrix):\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "\n",
    "        predicted_ratings = torch.matmul(user_embeddings, item_embeddings.T)\n",
    "        interaction_tensor = torch.tensor(interaction_matrix.values, dtype=torch.float32)\n",
    "        target= interaction_tensor\n",
    "\n",
    "        rmse = np.sqrt(mean_squared_error(target, predicted_ratings))  # Compute RMSE\n",
    "        print(f'RMSE: {rmse:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zyMyvKQcZ7X5"
   },
   "outputs": [],
   "source": [
    "def predict_new_user_rating(item_embeddings, masked_array, num_users=num_users):\n",
    "    item_embeddings = item_embeddings.detach().numpy()\n",
    "    masked_array = np.array(masked_array, dtype=np.float32)\n",
    "\n",
    "    masked_array = masked_array.reshape(-1, 1)  # Shape: (num_items, 1)\n",
    "    weighted_sum = np.sum(item_embeddings * masked_array, axis=0)\n",
    "    sum_of_weights = np.sum(masked_array)\n",
    "    new_user_embedding = weighted_sum / sum_of_weights\n",
    "    predicted_ratings = np.dot(item_embeddings, new_user_embedding)\n",
    "\n",
    "    return predicted_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nnwzBffw00cP"
   },
   "outputs": [],
   "source": [
    "def prediction_test(num_users, interaction_array, item_embeddings):\n",
    "    metric=0\n",
    "    for i in range(len(interaction_array) - num_users, len(interaction_array)):\n",
    "        normal_test = interaction_array[i]\n",
    "        non_zero_indices = np.nonzero(normal_test)[0]\n",
    "        num_values_to_keep = len(non_zero_indices) // 2\n",
    "        selected_indices = np.random.choice(non_zero_indices, size=num_values_to_keep, replace=False)\n",
    "        masked_array = np.zeros_like(normal_test)\n",
    "        masked_array[selected_indices] = normal_test[selected_indices]\n",
    "        prediction = predict_new_user_rating(item_embeddings, masked_array)\n",
    "        rmse = np.sqrt(np.mean((prediction - normal_test) ** 2))\n",
    "        metric+= rmse\n",
    "    return metric/num_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "787-9GTBH9GA",
    "outputId": "3d36f0bb-8616-4a5d-af77-3b2bc6d831ce"
   },
   "outputs": [],
   "source": [
    "# Evaluate on training data\n",
    "evaluate_gcn_model(model1, user_embeddings, item_embeddings,  interaction_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L_EuNyEXZu7v"
   },
   "source": [
    "Testing for RECnormal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DSH4B2Sg2Ryi",
    "outputId": "5c44465d-9c7f-40ee-b8ee-27afdb84ba2e"
   },
   "outputs": [],
   "source": [
    "print(prediction_test(50, interaction_array, old_item_embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "09fR5qvmZuLW"
   },
   "outputs": [],
   "source": [
    "# normal_test = interaction_array[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SPZy295kakuS"
   },
   "outputs": [],
   "source": [
    "# num_values_to_keep = 20\n",
    "# non_zero_indices = np.nonzero(normal_test)[0]\n",
    "# selected_indices = np.random.choice(non_zero_indices, size=num_values_to_keep, replace=False)\n",
    "# masked_array = np.zeros_like(normal_test)\n",
    "# masked_array[selected_indices] = normal_test[selected_indices]\n",
    "# print(masked_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kDc64Tu9awcD"
   },
   "outputs": [],
   "source": [
    "# prediction = predict_new_user_rating(old_item_embeddings, masked_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TjtWDakZa2ym"
   },
   "outputs": [],
   "source": [
    "# rmse = np.sqrt(np.mean((prediction - normal_test) ** 2))\n",
    "# print(\"RMSE:\", rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rpE7iN7dH9GB",
    "outputId": "6c47a559-4a85-4a85-a5f2-225d0ca100df"
   },
   "outputs": [],
   "source": [
    "# get the adversarial exmaples\n",
    "interaction_array_manipulated = adversarial_manipulation(user_embeddings, item_embeddings, interaction_array, model1, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0Qiyxl5KH9GB"
   },
   "source": [
    "### Phase 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dqe75o8BH9GB",
    "outputId": "09b8efc1-6c90-49d5-8522-e2bacc7c68e0"
   },
   "outputs": [],
   "source": [
    "user_indices, item_indices = np.nonzero(interaction_array_manipulated)  # Get indices of non-zero elements\n",
    "\n",
    "# Retrieve the corresponding ratings from interaction_array\n",
    "ratings = interaction_array_manipulated[user_indices, item_indices]\n",
    "\n",
    "# Create a DataFrame similar to the original ratings DataFrame\n",
    "reconstructed_ratings = pd.DataFrame({\n",
    "    'user_idx': user_indices,\n",
    "    'item_idx': item_indices,\n",
    "    'rating': ratings\n",
    "})\n",
    "\n",
    "# Print to verify\n",
    "print(reconstructed_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QR2WVV0UIMJH"
   },
   "outputs": [],
   "source": [
    "ratings = reconstructed_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kzmpqkefIlIb"
   },
   "outputs": [],
   "source": [
    "train_size = int(len(ratings))\n",
    "val_size = int(0 * len(ratings))\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(ratings, [train_size, val_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wPMKB7x5H9GB"
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(UserItemDataset(ratings.iloc[train_dataset.indices]), batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vz2sM3cfJlgz"
   },
   "outputs": [],
   "source": [
    "users = ratings['user_idx'].unique()\n",
    "items = ratings['item_idx'].unique()\n",
    "\n",
    "# Create mappings from user/item IDs to indices (used for embedding)\n",
    "user_to_idx = {user: idx for idx, user in enumerate(users)}\n",
    "item_to_idx = {item: idx for idx, item in enumerate(items)}\n",
    "\n",
    "# Convert user and item IDs in ratings to indices\n",
    "ratings['user_idx'] = ratings['user_idx'].apply(lambda x: user_to_idx[x])\n",
    "ratings['item_idx'] = ratings['item_idx'].apply(lambda x: item_to_idx[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-j2uuk0NIqW8"
   },
   "outputs": [],
   "source": [
    "num_users = len(users)\n",
    "num_items = len(items)\n",
    "embedding_size = 50  # This is a tunable hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XnZveAmYJ89O"
   },
   "outputs": [],
   "source": [
    "mf_model2 = MFModel(num_users, num_items, embedding_size).to(device)\n",
    "optimizer = optim.Adam(mf_model2.parameters(), lr=0.001)  # Adam optimizer\n",
    "loss_fn = nn.MSELoss()  # Loss function (Mean Squared Error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "necKvJYEK6ka",
    "outputId": "06d3a58d-d7ec-4247-f5d6-75f392276e3c"
   },
   "outputs": [],
   "source": [
    "print(num_users, num_items, mf_model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4CjyVzxWLDNy",
    "outputId": "b9e41251-c6d6-4b12-e078-62bae41891b0"
   },
   "outputs": [],
   "source": [
    "train_mf_model(mf_model2, train_loader, optimizer, loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vYIdLAdTLQby"
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    user_embeddings = mf_model2.user_embedding.weight.cpu().numpy()\n",
    "    item_embeddings = mf_model2.item_embedding.weight.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cgcSg49NLQby",
    "outputId": "267929b6-2c5f-4bb8-d497-2ac4f4cfe298"
   },
   "outputs": [],
   "source": [
    "print(user_embeddings.shape)\n",
    "print(user_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CxF_rMTXLucE",
    "outputId": "24f814f1-5801-4a85-ea16-25dc971cf794"
   },
   "outputs": [],
   "source": [
    "train_graph_data = create_graph_data(ratings,num_users,user_embeddings,item_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BgZaYzkIMPzj"
   },
   "outputs": [],
   "source": [
    "model2 = GCNModel(in_channels=embedding_size, hidden_channels=64, out_channels=32).to(device)\n",
    "gcn_optimizer = optim.Adam(model2.parameters(), lr=0.01)\n",
    "gcn_loss_fn = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zq6_6ExFYJCG"
   },
   "outputs": [],
   "source": [
    "interaction_matrix_manipulated = ratings.pivot(index='user_idx', columns='item_idx', values='rating').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "198Y0mdTMju1",
    "outputId": "de27a578-60b4-44ae-f75a-70b8070a5354"
   },
   "outputs": [],
   "source": [
    "user_embeddings, item_embeddings= train_gcn_model(model2, train_graph_data, gcn_optimizer, gcn_loss_fn, interaction_matrix_manipulated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XzpUi0fXM3ba",
    "outputId": "4c6c0fb2-6e33-4438-ebc8-e2c94ef396d3"
   },
   "outputs": [],
   "source": [
    "evaluate_gcn_model(model2, user_embeddings, item_embeddings,  interaction_matrix_manipulated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6LGW0cU4dudX"
   },
   "source": [
    "Compare the rmse for all 3 models calculated by predicting ratings for a new user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q8h9-Died4bW"
   },
   "outputs": [],
   "source": [
    "# adversarial_interactions= interaction_array_manipulated[610:]\n",
    "# adversarial_interactions.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dolBJnHAInQs"
   },
   "source": [
    "Testing for RECsecure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sgz9yFo72sOm",
    "outputId": "94c2bd54-eee7-459d-ce2f-6ee9c3832d71"
   },
   "outputs": [],
   "source": [
    "print(prediction_test(50, interaction_array_manipulated, item_embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "riLQDwgMHkBB"
   },
   "outputs": [],
   "source": [
    "# adversarial_test = adversarial_interactions[np.random.choice(adversarial_interactions.shape[0])]\n",
    "# num_values_to_keep = 2000\n",
    "# non_zero_indices = np.nonzero(adversarial_test)[0]\n",
    "# selected_indices = np.random.choice(non_zero_indices, size=num_values_to_keep, replace=False)\n",
    "# masked_array = np.zeros_like(adversarial_test)\n",
    "# masked_array[selected_indices] = adversarial_test[selected_indices]\n",
    "# print(masked_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fIe8Tc-bI4-l"
   },
   "outputs": [],
   "source": [
    "# prediction = predict_new_user_rating(item_embeddings, masked_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ypi1NfkxXtOg"
   },
   "outputs": [],
   "source": [
    "# rmse = np.sqrt(np.mean((prediction - adversarial_test) ** 2))\n",
    "# print(\"RMSE:\", rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R_woB32vcnYg"
   },
   "source": [
    "Testing for RECmani"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f9_9yun-3GNu",
    "outputId": "98be69f6-6d44-4041-fb48-aec6a752fc72"
   },
   "outputs": [],
   "source": [
    "print(prediction_test(50, interaction_array_manipulated, old_item_embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aCBctVs1ctPZ"
   },
   "outputs": [],
   "source": [
    "# prediction = predict_new_user_rating(old_item_embeddings, masked_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gEZ3EL90czLg"
   },
   "outputs": [],
   "source": [
    "# rmse = np.sqrt(np.mean((prediction - adversarial_test) ** 2))\n",
    "# print(\"RMSE:\", rmse)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
